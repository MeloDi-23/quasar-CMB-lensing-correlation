{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycorr\n",
    "# import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import Planck18 as cosmos\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from sklearn.neighbors import KDTree\n",
    "h = cosmos.H0.value/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasar = np.load('../catalogue/quasar_lss_all.npy')\n",
    "random = np.load('../catalogue/random_quasar_lss_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label.bin', 'rb') as f:\n",
    "    npix = np.load(f)\n",
    "    npix_r = np.load(f)\n",
    "pix = np.unique(npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros_like(npix)\n",
    "label_r = np.zeros_like(npix_r)\n",
    "all_pix = np.unique(npix)\n",
    "for i, p in enumerate(all_pix):\n",
    "    label[npix==p] = i\n",
    "    label_r[npix_r==p] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_cov_q = cosmos.comoving_distance(quasar['z']).to(u.Mpc).value*h\n",
    "dis_cov_r = cosmos.comoving_distance(random['z']).to(u.Mpc).value*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.cosmology import Planck18 as cosmos\n",
    "import astropy.coordinates as coo\n",
    "h = cosmos.H0.value/100\n",
    "\n",
    "Nbins = 15\n",
    "rp_bin = np.geomspace(3, 100, Nbins+1)\n",
    "pimax = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_q = np.vstack([quasar['ra'], quasar['dec'], dis_cov_q])\n",
    "pos_r = np.vstack([random['ra'], random['dec'], dis_cov_r])\n",
    "correlation_func = pycorr.correlation_function.TwoPointCorrelationFunction(\n",
    "    'rppi', (rp_bin, np.linspace(-pimax, pimax, 2*pimax+1, endpoint=True)),\n",
    "    pos_q, pos_q, pos_r, pos_r, \n",
    "    data_weights1=quasar['w'],\n",
    "    data_weights2=quasar['w'],\n",
    "    # data_samples1=label,\n",
    "    # data_samples2=label,\n",
    "    # randoms_samples1=label_r,\n",
    "    # randoms_samples2=label_r,\n",
    "    randoms_weights1=random['w'],\n",
    "    randoms_weights2=random['w'],\n",
    "    estimator='landyszalay',\n",
    "    position_type='rdd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlation_func.get_corr(return_sep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = corr[0]\n",
    "pi = corr[1]\n",
    "xi = corr[2]\n",
    "# cov = corr[3]\n",
    "wp = xi.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auto_corr_pycorr.npy', 'wb') as f:\n",
    "    np.save(f, rp)\n",
    "    np.save(f, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasar_SDSS = fits.getdata('/uufs/chpc.utah.edu/common/home/astro/zheng/hd/data/SDSS16Q/DR16Q_v4.fits')\n",
    "tree = KDTree(np.c_[quasar_SDSS['RA'], quasar_SDSS['DEC']], metric='euclidean')\n",
    "que = tree.query(np.c_[quasar['ra'], quasar['dec']])\n",
    "valid = que[0].flatten() < 5/3600\n",
    "index = que[1].flatten()\n",
    "\n",
    "M_I = quasar_SDSS['M_I'][index]\n",
    "M_I[~valid] = np.nan\n",
    "bins = np.linspace(0.8, 2.2, 30)            # the z cut applied to quasar lss all\n",
    "result = np.digitize(quasar['z'], bins)\n",
    "kind = np.zeros(len(quasar), int)\n",
    "middles = []\n",
    "high = []\n",
    "low = []\n",
    "for i in range(1, 30):\n",
    "    index = np.where(result == i)[0]\n",
    "    M = M_I[index]\n",
    "    middle = np.percentile(M[~np.isnan(M)], 50)\n",
    "    high.append(index[M <= middle])\n",
    "    low.append(index[M >= middle])\n",
    "\n",
    "index_h = np.concatenate(high)\n",
    "index_l = np.concatenate(low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pos_r = np.vstack([random['ra'], random['dec'], dis_cov_r])\n",
    "\n",
    "quasar_sub = quasar[index_h]\n",
    "distance_sub = dis_cov_q[index_h]\n",
    "pos_q = np.vstack([quasar_sub['ra'], quasar_sub['dec'], distance_sub])\n",
    "correlation_func_h = pycorr.correlation_function.TwoPointCorrelationFunction(\n",
    "    'rppi', (rp_bin, np.linspace(-pimax, pimax, 2*pimax+1, endpoint=True)),\n",
    "    pos_q, pos_q, pos_r, pos_r, \n",
    "    data_weights1=quasar_sub['w'],\n",
    "    data_weights2=quasar_sub['w'],\n",
    "    # data_samples1=label,\n",
    "    # data_samples2=label,\n",
    "    # randoms_samples1=label_r,\n",
    "    # randoms_samples2=label_r,\n",
    "    randoms_weights1=random['w'],\n",
    "    randoms_weights2=random['w'],\n",
    "    estimator='landyszalay',\n",
    "    position_type='rdd'\n",
    ")\n",
    "quasar_sub = quasar[index_l]\n",
    "distance_sub = dis_cov_q[index_l]\n",
    "pos_q = np.vstack([quasar_sub['ra'], quasar_sub['dec'], distance_sub])\n",
    "correlation_func_l = pycorr.correlation_function.TwoPointCorrelationFunction(\n",
    "    'rppi', (rp_bin, np.linspace(-pimax, pimax, 2*pimax+1, endpoint=True)),\n",
    "    pos_q, pos_q, pos_r, pos_r, \n",
    "    data_weights1=quasar_sub['w'],\n",
    "    data_weights2=quasar_sub['w'],\n",
    "    # data_samples1=label,\n",
    "    # data_samples2=label,\n",
    "    # randoms_samples1=label_r,\n",
    "    # randoms_samples2=label_r,\n",
    "    randoms_weights1=random['w'],\n",
    "    randoms_weights2=random['w'],\n",
    "    estimator='landyszalay',\n",
    "    position_type='rdd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlation_func_h.get_corr(return_sep=True)\n",
    "rp = corr[0]\n",
    "pi = corr[1]\n",
    "xi = corr[2]\n",
    "wp = xi.sum(axis=1)\n",
    "\n",
    "with open('auto_corr_pycorr_h.npy', 'wb') as f:\n",
    "    np.save(f, rp)\n",
    "    np.save(f, wp)\n",
    "\n",
    "corr = correlation_func_l.get_corr(return_sep=True)\n",
    "rp = corr[0]\n",
    "pi = corr[1]\n",
    "xi = corr[2]\n",
    "wp = xi.sum(axis=1)\n",
    "\n",
    "with open('auto_corr_pycorr_l.npy', 'wb') as f:\n",
    "    np.save(f, rp)\n",
    "    np.save(f, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
